<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Marijn van Vliet" />
  <link rel="stylesheet" href="../styles.css">
  <script src="../logoswitch.js" defer></script>
</head>
<body>
  <main>
    <a class="back" href="../index.html"><img src="../images/nav_back.svg">Back to the CMHC lab page</a>
    <h1>Convolutional networks can model the functional modulation of MEG responses during reading</h1>
    <p class="authors">
      Marijn van Vliet<sup>1,*</sup>, Oona Rinkinen<sup>1</sup>, Takao Shimizu<sup>1</sup>, Anni-Mari Niskanen<sup>1</sup>, Barry Devereux<sup>3</sup>, and Riitta Salmelin<sup>1,2</sup>

      <sup>1</sup> Department of Neuroscience and Biomedical Engineering, Aalto University, Finland
      <sup>2</sup> Aalto NeuroImaging, Aalto University, Finland
      <sup>3</sup> School of Electronics, Electrical Engineering and Computer Science, Queen's University Belfast, United Kingdom
      <sup>*</sup> Corresponding author: <a href="mailto:marijn.vanvliet@aalto.fi">marijn.vanvliet@aalto.fi</a>
    </p>

    <nav>
      <a href="#summary"><img src="../images/nav_abstract.svg"><br>Summary</a>
      <a href="poster.pdf"><img src="../images/nav_poster.svg"><br>Poster</a>
      <a href="https://doi.org/10.7554/eLife.96217.1"><img src="../images/nav_full_paper.svg"><br>Full Paper</a>
      <a href="https://users.aalto.fi/~vanvlm1/network_explorer/"><img src="../images/nav_model.svg">Model</a>
      <a href="https://github.com/wmvanvliet/viswordrec-baseline"><img src="../images/nav_code.svg"><br>Code</a>
      <a href="https://osf.io/nu2ep"><img src="../images/nav_data.svg"><br>Data</a>
    </nav>

    <section>
      <h2 id="summary">Project Summary</h2>

      <p>
        To better understand the computational steps that the brain performs during reading, we used a convolutional neural network as a computational model of visual word recognition, the first stage of reading.
        In contrast to traditional models of reading, our model directly operates on the pixel values of an image containing text, and has a large vocabulary of 10k Finnish words.
        The same stimuli can thus be presented unmodified to both the model and human volunteers in an MEG scanner.
        In a direct comparison between model and brain activity, we show that the model accurately predicts the amplitude of three evoked MEG response components commonly observed during reading.
        We conclude that the deep learning techniques that revolutionized models of object recognition can also create models of reading that can be straightforwardly compared to neuroimaging data, which will greatly facilitate testing and refining theories on language processing in the brain.
      </p>

      <p>Here is a video presentation of the project. A talk given at the Neuromatch conference in 2021:</p>

      <a class="talk" href="https://youtu.be/Cqbjz6eHTLc"><img src="../images/talk1.jpg"></a>

      <p>
        Below is a graphical summary of the main results: comparing model- to brain-activity. The same set of visual stimuli (color coded in the figure) were presented to human volunteers in an MEG experiment, and to a VGG-11 convolutional network. The amount of brain activity to each stimulus was quantified at three locations along the cortex (equivalent current dipole (ECD) modeling, <b>A</b>) and compared to the sum ReLu activity at the layers of the model (<b>B</b>):
      </p>

      <img src="results.png" width="100%" style="margin-top: 2ex"/>
    </section>
    <div id="logos">
      <a href="https://aalto.fi"><img src="../images/logo_aalto1.svg" alt="Aalto University, School of Science" onload="logoSwitch(this)"/></a>
      <a href="https://www.aalto.fi/en/department-of-neuroscience-and-biomedical-engineering"><img src="../images/logo_nbe.svg" alt="Department of Neuroimaging and Biomedical Engineering"/></a>
    </div>
  </main>
</body>
</html
