<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <meta name="author" content="Marijn van Vliet">
    <link rel="stylesheet" href="../styles.css">
    <link rel="stylesheet" href="style.css">
    <script src="word2vec.js" defer></script>
    <script defer>
      var vectors = undefined;
      window.onload = async function(e) {
        vectors = await loadVectors('glove-en');
      };
    </script>
  </head>
  <body>
  <main>
    <a class="back" href="../index.html"><img src="../images/nav_back.svg">Back to the CMHC lab page</a>
    <h1>Word Comparison through Semantic Projection</h1>
    <p>Welcome to the word comparison experiment, based on the work of <a href="https://arxiv.org/pdf/1802.01241.pdf">Grand et al. <code>[1]</code></a>. Describe a dimension by thinking of words that create a contrast. Make sure to enter them &quot;pairwise&quot;, meaning that the first negative word is the antonym of the first positive word. Finally, enter some words to be compared along the dimension.</p>

    <p id="loading-p">
      <label for="loading-w2v">Downloading English GloVe vectors:</label>
      <progress id="loading-w2v" value="0" max="1"></progress>
    </p>
    <p>
      <form id="query-form" onsubmit="return getComparison(this)">
        <h2>Step 1: Define a dimension along which to compare</h2>
        <label for="negative_words">Negative words:</label>
        <input type="text" id="negative_words" autofocus="1" placeholder="small, tiny, puny" required><br>
        <label for="positive_words">Positive words:</label>
        <input type="text" id="positive_words" placeholder="large, big, huge" required>

        <h2>Step 2: Give some words to compare with each other</h2>
        Words to compare: <input type="text" id="words" placeholder="mouse, elephant" required>
        <button type="submit">Compare</button>
      </form>
    </p>
    <p id="result"></p>
    
    <h2>Examples</h2>
    <p>Here are some example dimensions to try:</p>
    <ul>
      <li><strong>age:</strong> old ancient elderly - young youth child</li>
      <li><strong>arousal:</strong> interesting exciting fun - boring unexciting dull</li>
      <li><strong>cost:</strong> expensive costly fancy - inexpensive cheap budget</li>
      <li><strong>danger:</strong> dangerous deadly threatening - safe harmless calm</li>
      <li><strong>gender:</strong> male masculine man - female feminine woman</li>
      <li><strong>intelligence:</strong> intelligent smart wise - stupid dumb idiotic</li>
      <li><strong>location:</strong> indoor indoors inside - outdoor outdoors outside</li>
      <li><strong>loudness:</strong> loud deafening noisy - soft silent quiet</li>
      <li><strong>political:</strong> democrat liberal progressive - republican conservative redneck</li>
      <li><strong>religiosity:</strong> religious spiritual orthodox - atheist secular agnostic</li>
      <li><strong>size:</strong> large big huge - small little tiny</li>
      <li><strong>speed:</strong> fast speedy quick - slow sluggish gradual</li>
      <li><strong>temperature:</strong> hot warm tropical - cold cool frigid</li>
      <li><strong>valence:</strong> good great happy - bad awful sad</li>
      <li><strong>wealth:</strong> rich wealthy privileged - poor poverty underprivileged</li>
      <li><strong>weight:</strong> heavy fat thick - light skinny thin</li>
      <li><strong>wetness:</strong> wet water ocean - dry country land</li>
    </ul>
   
    <h2>Where does the data come from?</h2>

    <p>The corpus that was used to create the model is a crawl of <a href="https://wikipedia.com">Wikipedia</a> done in 2014, plus the <a href="https://catalog.ldc.upenn.edu/LDC2011T07">Gigaword 5</a> corpus of the Linguistic Data Consortium. The model contains 300-dimensional vectors for 6 billion words and phrases, although in this example only the top 100k most common words are present to reduce download times. The phrases were obtained using a simple data-driven approach described in <code>[2]</code>. The model is available here: <a href="https://nlp.stanford.edu/projects/glove/">https://nlp.stanford.edu/projects/glove/</a>.</p>

    <h2>More information about the comparison algorithm</h2>

    <p>To be clear, Aalto University's CMHC lab has nothing to do with the comparison algorithm, we just showcase it on our website. The comparison algorithm was published here:</p>

    <p><code>[1]</code>Gabriel Grand, Idan Asher Blank, Francisco Pereira, and Evelina Fedorenko. <a href="https://arxiv.org/pdf/1802.01241.pdf">Semantic projection recovers rich human knowledge of multiple object features from word embeddings</a>. Nature Human Behavior, 2022.</p>

    <p>The algorithm works by first creating a difference vectors between the GloVe vectors of two words (labeled &quot;positive&quot; and &quot;negative&quot; in the interface above). Then, the GloVe vectors of each of the words to compare are projected onto the difference vector. To obtain a more reliable difference vector, we can average across multiple difference vectors, hence you are able to specify multiple &quot;positive&quot; and &quot;negative&quot; words in the interface.</p>

    <h2>More information about the GloVe algorithm</h2>

    <p><a href="https://nlp.stanford.edu/projects/glove/"/>GloVe</a> is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.</p>

    <p><code>[2]</code>Jeffrey Pennington, Richard Socher, and Christopher D. Manning. <a href="https://nlp.stanford.edu/pubs/glove.pdf">GloVe: Global Vectors for Word Representation.</a> 2014.

    <img id="aalto-img" src="aalto.png" alt="Aalto University Logo"/>
  </main>
  </body>
</html>
